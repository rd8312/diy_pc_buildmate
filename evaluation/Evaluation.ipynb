{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 套件與資料載入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "# sys.path.append('.')\n",
    "\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "import ast\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#   import argparse\n",
    "\n",
    "#     parser = argparse.ArgumentParser(description='')\n",
    "#     parser.add_argument('--config_path', dest='config_path')\n",
    "#     parameter_args = parser.parse_args()\n",
    "\n",
    "#     config_path = parameter_args.config_path\n",
    "\n",
    "config_path = '../config/few_config.json'\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    config = json.load(f)\n",
    "os.environ['OPENAI_API_KEY'] = config['OpenAI_api_key']\n",
    "\n",
    "test_dataset_path = config['test_dataset_path']\n",
    "with open(test_dataset_path, 'r') as f:\n",
    "    test_set = json.load(f)\n",
    "    \n",
    "only_for_classification = test_set['only_for_classification']\n",
    "SQL_PROMPT = config['GPTs']['SQL']['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/llm/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from chains import make_chain, make_memory, Chain_manager\n",
    "\n",
    "chain_manager = Chain_manager(config)\n",
    "classifier_chain, _ = chain_manager.make_chain('Classifier')\n",
    "general_chain, _ = chain_manager.make_chain('General')\n",
    "db_chain, _ = chain_manager.make_chain('SQL')\n",
    "retrieve_chain, _ = chain_manager.make_chain('Retrieve')\n",
    "consultant_chain, memory = chain_manager.make_chain('Consultant') # Netizen Consultant\n",
    "\n",
    "comment_chain, _memory = chain_manager.make_chain('Comment')\n",
    "score_chain, _ = chain_manager.make_chain('Score')\n",
    "recommend_eva_chain, _ = chain_manager.make_chain('Recommend_evaluation')\n",
    "consultant_comment_chain, _ = chain_manager.make_chain('Consultant_Comment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型預測: 100%|██████████| 4/4 [00:33<00:00,  8.45s/it]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "time1 = time.time()\n",
    "\n",
    "\n",
    "classifier_error_examples = []\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    \n",
    "    for data in tqdm(test_set['data_list'], desc='模型預測'):\n",
    "        \n",
    "        question_class = data['class']\n",
    "        question = data['question']\n",
    "        \n",
    "        if question_class != '6':\n",
    "            predict_class = classifier_chain.invoke({\"question\": f\"{question}\"})\n",
    "            predict_class = re.findall('\\d', predict_class)[0]\n",
    "        elif question_class == '6':\n",
    "            predict_class = '6'\n",
    "        \n",
    "        data['predict_class'] = predict_class\n",
    "        \n",
    "        if predict_class == '6':\n",
    "            try:\n",
    "                question_childs = data['question_childs']\n",
    "                memory.clear()\n",
    "                conversation = ''\n",
    "                for question in question_childs:\n",
    "                    input_message = {\"question\": f\"{question}\"}\n",
    "                    answer = consultant_chain.invoke(input_message)  \n",
    "                    memory.save_context(input_message, {\"answer\": answer})\n",
    "                    \n",
    "                    data['answer_childs'].append(answer)\n",
    "                    conversation += f'諮詢的問題：{question}\\n諮詢的回覆：{answer}\\n'\n",
    "                data['predict'] = conversation\n",
    "            except Exception as e:\n",
    "                print(f'預測程式錯誤\\nChain {predict_class}\\n錯誤原因：{e}')\n",
    "        \n",
    "        elif only_for_classification:\n",
    "            pass\n",
    "        \n",
    "        elif question_class == predict_class:\n",
    "            \n",
    "            try:\n",
    "                \n",
    "                if predict_class == '1':\n",
    "                    \n",
    "                    predict = general_chain.invoke({\"question\": f\"{question}\"})                \n",
    "                \n",
    "                if predict_class == '2':\n",
    "                    question = question + SQL_PROMPT\n",
    "                    return_data = db_chain.invoke(question)\n",
    "                    if return_data['result']:\n",
    "                        predict = ast.literal_eval(return_data['result'])[0][0]\n",
    "                    else:\n",
    "                        predict = ''\n",
    "                    \n",
    "                if predict_class == '4':\n",
    "                    \n",
    "                    predict = retrieve_chain.invoke(question)\n",
    "                    predict = '這邊有找到一則與您需求相近的清單給您：\\n' + predict\n",
    "                    \n",
    "                data['predict'] = predict\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f'預測程式錯誤\\nChain {predict_class}\\n錯誤原因：{e}')\n",
    "        else:\n",
    "            classifier_error_examples.append(question)\n",
    "            print(f'[分類錯誤]問題：{question}\\n真實類別：{question_class}\\n預測類別：{predict_class}')\n",
    "\n",
    "time2 = time.time()\n",
    "process_time = time2 - time1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 評估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型評分:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型評分: 100%|██████████| 4/4 [00:13<00:00,  3.42s/it]\n"
     ]
    }
   ],
   "source": [
    "classifier_error_examples = []\n",
    "\n",
    "for data in tqdm(test_set['data_list'], desc='模型評分'):\n",
    "    \n",
    "    question_class = data['class']\n",
    "    predict_class = data['predict_class']\n",
    "    \n",
    "    if predict_class == '6':\n",
    "        question = data['question']\n",
    "        predict = data['predict']\n",
    "        try:\n",
    "            question = '想要一台' + question\n",
    "            evaluation = consultant_comment_chain.invoke({\"question\": f\"{question}\", \"predict\": f\"{predict}\"})\n",
    "            score = score_chain.invoke({\"question\": f\"{question}\", \"answer\": f\"{predict}\", \"evaluation\": f\"{evaluation}\"})\n",
    "            score = re.findall(r'\\d+', score)[0]\n",
    "            data['evaluation'] = evaluation\n",
    "            data['score'] = score\n",
    "        except Exception as e:\n",
    "            print(f'評估過程發生錯誤\\n錯誤原因：{e}')\n",
    "            \n",
    "    elif only_for_classification:\n",
    "        pass\n",
    "    \n",
    "    elif question_class == predict_class:\n",
    "        question = data['question']\n",
    "        predict = data['predict']\n",
    "        try:\n",
    "            \n",
    "            if predict_class == '1':\n",
    "                \n",
    "                evaluation = comment_chain.invoke({\"question\": f\"{question}\", \"answer\": f\"{predict}\"})\n",
    "                evaluation = evaluation.replace('輸出:', '').replace(' ', '')\n",
    "                \n",
    "                score = score_chain.invoke({\"question\": f\"{question}\", \"answer\": f\"{predict}\", \"evaluation\": f\"{evaluation}\"})\n",
    "                score = re.findall(r'\\d+', score)[0]\n",
    "                    \n",
    "            if predict_class == '2':\n",
    "                \n",
    "                answer = data['answer']\n",
    "                answer_type = data['answer_type']\n",
    "\n",
    "                # 更複雜的計分規則，可以來討論，例如型號與名稱，可以接受模糊比對\n",
    "                \n",
    "                if answer_type == 'error':\n",
    "                    if answer == '':\n",
    "                        score = 10\n",
    "                    else:\n",
    "                        score = 0\n",
    "                elif predict == '':\n",
    "                    score = 0\n",
    "                elif answer_type == 'int':\n",
    "                    if int(answer) == int(predict):\n",
    "                        score = 10\n",
    "                    else:\n",
    "                        score = 0\n",
    "                elif answer_type == 'str':\n",
    "                    if answer in predict or answer in predict:\n",
    "                        score = 10\n",
    "                    else:\n",
    "                        score = 0\n",
    "                \n",
    "                evaluation = ''\n",
    "                \n",
    "                if score == 0:\n",
    "                    print(f'\\n[SQL Error]\\nType: {answer_type}\\nQuestion: {question}\\nAnswer: {answer}\\nPredict: {predict}\\n')\n",
    "                \n",
    "            if predict_class == '4':\n",
    "                \n",
    "                evaluation = recommend_eva_chain.invoke({\"question\": f\"{question}\", \"predict\": f\"{predict}\"})\n",
    "                score = score_chain.invoke({\"question\": f\"{question}\", \"answer\": f\"{predict}\", \"evaluation\": f\"{evaluation}\"})\n",
    "                score = re.findall(r'\\d+', score)[0]\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f'評估過程發生錯誤\\n錯誤原因：{e}')\n",
    "        data['evaluation'] = evaluation\n",
    "        data['score'] = score\n",
    "        \n",
    "    else:\n",
    "        error_example = {}\n",
    "        data['score'] = 0\n",
    "        classifier_error_examples.append(data)\n",
    "        \n",
    "if classifier_error_examples and only_for_classification: print(classifier_error_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分數計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Score: 10.0\n",
      "General Score: 9.0 \n",
      "SQL Score: 10.0 \n",
      "Retrieve Score: 8.0 \n",
      "Consultant Score: 9.0 \n",
      "=========================\n",
      "Response count: 1005\n",
      "Data 1 and 5 num: 8\n",
      "Cost: 0.0126165\n",
      "Token: 8059\n",
      "Inference time 33.89316129684448\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "classifier_predict = 0\n",
    "consultant_num = 0\n",
    "\n",
    "class_1_scores = []\n",
    "class_2_scores = []\n",
    "class_4_scores = []\n",
    "class_6_scores = []\n",
    "\n",
    "total_response_count = 0\n",
    "data_1_5_num = 0\n",
    "\n",
    "for data in test_set['data_list']:\n",
    "    \n",
    "    data_class = data['class'] \n",
    "    predict_class = data['predict_class'] \n",
    "    \n",
    "    \n",
    "    if predict_class == data_class:\n",
    "        \n",
    "        if predict_class == '6':\n",
    "            data_score = data['score'] \n",
    "            class_6_scores.append(data_score)\n",
    "            consultant_num += 1\n",
    "            for answer in data['answer_childs']:\n",
    "                total_response_count += len(answer)\n",
    "                data_1_5_num += 1\n",
    "            \n",
    "        elif only_for_classification:\n",
    "            classifier_predict += 1\n",
    "        else:\n",
    "            classifier_predict += 1\n",
    "            data_score = data['score'] \n",
    "            \n",
    "            if data_class == '1':\n",
    "                class_1_scores.append(data_score)\n",
    "                total_response_count += len(data['predict'])\n",
    "                data_1_5_num += 1\n",
    "            elif data_class == '2':\n",
    "                class_2_scores.append(data_score)\n",
    "            elif data_class == '4':\n",
    "                class_4_scores.append(data_score)\n",
    "\n",
    "if classifier_predict:\n",
    "    classifier_accuracy = int(classifier_predict / (len(test_set['data_list']) - consultant_num) *100) \n",
    "    classifier_average = float(classifier_predict / (len(test_set['data_list']) - consultant_num) * 10) \n",
    "else:\n",
    "    classifier_accuracy, classifier_average = 0, 0\n",
    "    \n",
    "if classifier_average:\n",
    "    test_set['Classifier Accuracy'] = classifier_accuracy\n",
    "    test_set['score_data']['Classifier'] = classifier_average\n",
    "    print(f'Classifier Score: {classifier_average}')\n",
    "\n",
    "if class_1_scores:\n",
    "    class_1_average = sum([int(num) for num in class_1_scores]) / len(class_1_scores)\n",
    "    test_set['score_data']['General'] = class_1_average\n",
    "    print(f'General Score: {class_1_average} ')\n",
    "    \n",
    "if class_2_scores:\n",
    "    class_2_average = sum([int(num) for num in class_2_scores]) / len(class_2_scores)\n",
    "    test_set['score_data']['SQL'] = class_2_average\n",
    "    print(f'SQL Score: {class_2_average} ')\n",
    "    \n",
    "if class_4_scores:\n",
    "    class_4_average = sum([int(num) for num in class_4_scores]) / len(class_4_scores)\n",
    "    test_set['score_data']['Retrieve'] = class_4_average\n",
    "    print(f'Retrieve Score: {class_4_average} ')\n",
    "    \n",
    "if class_6_scores:\n",
    "    class_6_average = sum([int(num) for num in class_6_scores]) / len(class_6_scores)\n",
    "    test_set['score_data']['Consultant'] = class_6_average\n",
    "    print(f'Consultant Score: {class_6_average} ')\n",
    "    \n",
    "test_set['Response count'] = total_response_count\n",
    "test_set['token'] = cb.total_tokens\n",
    "test_set['cost'] = cb.total_cost\n",
    "test_set['Inference time'] = process_time\n",
    "test_set['Data 1 and 5 num'] = data_1_5_num\n",
    "\n",
    "print('='*25)\n",
    "print(f'Response count: {total_response_count}')\n",
    "print(f'Data 1 and 5 num: {data_1_5_num}')\n",
    "print(f'Cost: {round(cb.total_cost, 15)}')\n",
    "print(f'Token: {cb.total_tokens}')\n",
    "print(f'Inference time', process_time)\n",
    "print('='*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 紀錄儲存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report path : ../report/2024-03-22 00-13-45.json\n"
     ]
    }
   ],
   "source": [
    "from units import get_time_text\n",
    "\n",
    "_, evaluation_datetime = get_time_text()\n",
    "test_set['Evaluation datetime'] = evaluation_datetime\n",
    "report_path = config['report_path']\n",
    "evaluation_json_path = f'{report_path}/{evaluation_datetime}.json'\n",
    "\n",
    "with open(evaluation_json_path, 'w') as rm:\n",
    "    json.dump(test_set, rm, ensure_ascii=False, indent=4)\n",
    "    \n",
    "print(f'Report path : {evaluation_json_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
